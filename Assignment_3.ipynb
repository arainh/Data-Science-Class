{
 "metadata": {
  "name": "",
  "signature": "sha256:feec31a72ad92fd51215aec425d42fe46b794f3f5e39ae58dc7e3fe0c8b05ea0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# CSCSI 4800|5800 Introduction to Data Science\n",
      "## Assignment 3: Parsing\n",
      "\n",
      "**NOTE** click near here to select this cell, esc-Enter will get you into cell edit mode, shift-Enter gets you back\n",
      "\n",
      "**Name**: April Hudspeth\n",
      "\n",
      "**Student ID**: 995032557"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This assignment explores the use of synthetic (XML) and natural language parsing for data preparation. It comprises 3 parts:\n",
      "1. Parse some data (Amazon product reviews) in XML to extract the text of the reviews. \n",
      "2. Parse the text reviews into Stanford dependencies using the Stanford Parser, with XML output\n",
      "3. Read the parsed sentences back into Python with the XML parser. \n",
      "\n",
      "We assume you have copied this notebook, the stanford parser archive, and the reviews archive (download from the course canvas) into the same directory. Unpack the later two:\n",
      "<pre>\n",
      "tar xvzf reviews.tar.gz\n",
      "tar xvzf stanfordparser.tar.gz\n",
      "</pre>\n",
      "\n",
      "and then copy the parser into /opt:\n",
      "\n",
      "<pre>\n",
      "sudo mv StanfordParser /opt\n",
      "</pre>\n",
      "\n",
      "finally, if you havent already done it, create a personal bin directory:\n",
      "<pre>\n",
      "mkdir ~/bin\n",
      "</pre>\n",
      "\n",
      "scripts or links in that directory will then be in your path. This will be useful for using the Stanford parser (and other tools) later. The path is set in your login script. To make it find the new bin directory you have to log out and log back in again. In the top right hand corner of the VM window you will find a gear-shaped icon. Clicking it yields a drop-down menu with a logout option. Logout, an then back in when you see the login screen. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part I: XML Parsing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will be using Python's ElementTree API which you can read about here:\n",
      "\n",
      "https://docs.python.org/2/library/xml.etree.elementtree.html\n",
      "\n",
      "Start by loading some XML data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lxml import etree\n",
      "import pandas as pd\n",
      "parser = etree.XMLParser(recover=True)\n",
      "tree = etree.parse('reviews/video/reviews.xml', parser)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "btw, the data is actually far-from-perfect XML. To see some of the defects, remove the argument \"parser\" from the last line, so that it tries instead to parse with a (default) strict parser. You will see it crash at an invalid char string somewhere in the file. You can fix this and find the next problem... But its better to use an auto-recovering parser like the one above. \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Q1: What kinds of error did you see in the file? XMLSyntaxError: PCDATA invalid Char value 26, line 41, column 386"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets look at the contents of this tree"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root=tree.getroot()\n",
      "root"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<Element reviews at 0x7f43a8e9a8c0>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nodes have a tag (a name), and possibly attributes (empty in this case)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root.tag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "'reviews'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root.attrib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "{}"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The children of the root node are accessible using square bracket notation. They will be individual reviews. You can then examine each review node's children by adding additional square bracket fields. Do this now and explore the parse tree. Compare with the file contents (use a text editor to see it). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<Element review at 0x7f3c0b83e950>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also use the colon notation to retrieve all the children of a node:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print root[22][:]\n",
      "print \"\"\n",
      "print root[22][0].tag, root[22][0].text\n",
      "print root[22][1].tag, root[22][1].text\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[<Element unique_id at 0x7f3c0b83e998>, <Element unique_id at 0x7f3c0b83eb48>, <Element asin at 0x7f3c0b83eb90>, <Element product_name at 0x7f3c0b83ebd8>, <Element product_type at 0x7f3c0b83ec20>, <Element product_type at 0x7f3c0b83ec68>, <Element helpful at 0x7f3c0b83ecb0>, <Element rating at 0x7f3c0b83ecf8>, <Element title at 0x7f3c0b83ed40>, <Element date at 0x7f3c0b83ed88>, <Element reviewer at 0x7f3c0b83edd0>, <Element reviewer_location at 0x7f3c0b83ee18>, <Element review_text at 0x7f3c0b83ee60>]\n",
        "\n",
        "unique_id \n",
        "6301609638:if_you_like_the_stage_production,_you_will_be_disappointed!:t._j._walker\n",
        "\n",
        "unique_id \n",
        "103260\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that same-named elements can occur multiple times, e.g. unique_id and product_type\n",
      "\n",
      "The \"contents\" of a node are usually held in its text field, which you access like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root[2][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<Element unique_id at 0x7f3c0b83ebd8>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root[2][0].text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'\\n1569494088:ambrose_bierce_is_a_better_authority:charlotte_tellson_\"the_keeper_of_bierce\"\\n'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can look at the contents of the other \"unique_id\" node:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root[2][1].text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'\\n10560\\n'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "the find() and findall() methods allow you to find one or (respectively) all the children of a node with a particular tag. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root[10].find('product_name').text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "'\\nThe Firm: Video: Tom Cruise,Jeanne Tripplehorn,Gene Hackman,Hal Holbrook,Terry Kinney,Wilford Brimley,Ed Harris,Holly Hunter,David Strathairn,Gary Busey,Steven Hill,Tobin Bell,Barbara Garrick,Jerry Hardin,Paul Calderon,Jerry Weintraub,Sullivan Walker,Karina Lombard,Margo Martindale,John Beal,Sydney Pollack\\n'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root.findall('review')[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[<Element review at 0x7f3c0b83ecf8>,\n",
        " <Element review at 0x7f3c0b83ee18>,\n",
        " <Element review at 0x7f3c0b83e950>,\n",
        " <Element review at 0x7f3c0b83eb90>,\n",
        " <Element review at 0x7f3c0b83ee60>,\n",
        " <Element review at 0x7f3c0b83eb00>,\n",
        " <Element review at 0x7f3c0b83eea8>,\n",
        " <Element review at 0x7f3c0b83eef0>,\n",
        " <Element review at 0x7f3c0b83ef38>,\n",
        " <Element review at 0x7f3c0b83ef80>]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root[3].find('review_text').text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "\"\\nthis is another story that I don't know if I like it or not because Amazon.com never sent it too me.  this has happened about 4/5 times.  While usually I have no problem getting movies, sometimes I do.  sending them e-mails doesn't seem to work.  If they didn't have the best prices for movies, I'd leave\\n\""
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the ElementTree methods to construct a dataframe containing 11 columns corresponding to the 11 distinct children node types of each review node. Each row should represent a single review. For nodes that may be repeated like \"unique_id\", include a list of the node values in that field."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "data = []\n",
      "j = 0   \n",
      "total = 0\n",
      "product_count = 0\n",
      "uid_count = 0\n",
      "reviews = list(root.findall(\"review\"))\n",
      "\n",
      "for i in range(len(reviews)):\n",
      "    elements = list(reviews[i])\n",
      "    d = {}\n",
      "    for el in elements:\n",
      "        total += 1\n",
      "        if el.tag in d:\n",
      "            if el.tag == \"product_type\":\n",
      "                product_count += 1\n",
      "            if el.tag == \"unique_id\":\n",
      "                uid_count += 1\n",
      "            d[el.tag] += \", \" + el.text\n",
      "        else:\n",
      "            try:\n",
      "                d[el.tag] = el.text\n",
      "            except UnicodeError:\n",
      "                d[el.tag] = ''\n",
      "    data.append(d)\n",
      "\n",
      "print data[0]\n",
      "print data[1]\n",
      "perf = pd.DataFrame(data)\n",
      "perf.head(n=5)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'rating': '\\n2.0\\n', 'product_type': '\\nvideo\\n, \\nvideo\\n', 'helpful': '\\n1 of 2\\n', 'asin': '\\nB00006IUOZ\\n', 'title': '\\nDisappointing in more ways than as a remake\\n', 'review_text': \"\\nIt's not just that this film is a bloated remake of a quick, clean, near-perfect minimalist thriller. It's not that much of the added material (particularly the internal affairs sub-plot) feels tacked-on and unnecessary. It's not even that Pacino's character is a toned-down shell of the dangerously off-kilter detective of the original, that one of the more complicated characters (Frya Selmer/Tanya Francke) has been reduced down to set dressing, or that the ending ruins the film's moral atmosphere. It's the fact that Nolan, a sublimely talented director, is unable to coax a believable performance from any of his leads. Pacino does the method-acting bit again, taking it over the top in every single scene; Hilary Swank plays a pale imitation of her better roles as the down-to-earth hometown girl; and Robin Williams--well, he's Robin Williams. The kids in this film, Katharine Isabelle and Jonathan Jackson, turn in fine performances that, while hardly career-makers (which they couldn't be, considering how far their roles have been pared down), are a refreshing change of pace from their adult contemporaries' mugging. See the film for their far-too-short performances, but make sure you rent it, and don't pay too much to do so\\n\", 'reviewer_location': '\\nparticularly the internal affairs sub-plot\\n', 'date': '\\nOctober 5, 2005\\n', 'reviewer': '\\nPipBoy\\n', 'product_name': \"\\nInsomnia: Video: Al Pacino,Martin Donovan (II),Robin Williams,Oliver 'Ole' Zemen,Hilary Swank,Paul Dooley,Nicky Katt,Larry Holden,Jay Brazeau,Lorne Cardinal,James Hutson,Andrew Campbell (IX),Paula Shaw (II),Crystal Lowe,Tasha Simms,Maura Tierney,Jonathan Jackson,Malcolm Boddington,Katharine Isabelle,Kerry Sandomirsky,Christopher Nolan\\n\", 'unique_id': '\\nB00006IUOZ:disappointing_in_more_ways_than_as_a_remake:pipboy\\n, \\n2740\\n'}\n",
        "{'rating': '\\n2.0\\n', 'product_type': '\\nvideo\\n, \\nvideo\\n', 'helpful': '\\n1 of 2\\n', 'asin': '\\nB00006JE7V\\n', 'title': '\\nDisappointing in more ways than as a remake\\n', 'review_text': \"\\nIt's not just that this film is a bloated remake of a quick, clean, near-perfect minimalist thriller. It's not that much of the added material (particularly the internal affairs sub-plot) feels tacked-on and unnecessary. It's not even that Pacino's character is a toned-down shell of the dangerously off-kilter detective of the original, that one of the more complicated characters (Frya Selmer/Tanya Francke) has been reduced down to set dressing, or that the ending ruins the film's moral atmosphere. It's the fact that Nolan, a sublimely talented director, is unable to coax a believable performance from any of his leads. Pacino does the method-acting bit again, taking it over the top in every single scene; Hilary Swank plays a pale imitation of her better roles as the down-to-earth hometown girl; and Robin Williams--well, he's Robin Williams. The kids in this film, Katharine Isabelle and Jonathan Jackson, turn in fine performances that, while hardly career-makers (which they couldn't be, considering how far their roles have been pared down), are a refreshing change of pace from their adult contemporaries' mugging. See the film for their far-too-short performances, but make sure you rent it, and don't pay too much to do so\\n\", 'reviewer_location': '\\nparticularly the internal affairs sub-plot\\n', 'date': '\\nOctober 5, 2005\\n', 'reviewer': '\\nPipBoy\\n', 'product_name': \"\\nInsomnia (2002) (Spanish) (Sub): Video: Al Pacino,Martin Donovan (II),Robin Williams,Oliver 'Ole' Zemen,Hilary Swank,Paul Dooley,Nicky Katt,Larry Holden,Jay Brazeau,Lorne Cardinal,James Hutson,Andrew Campbell (IX),Paula Shaw (II),Crystal Lowe,Tasha Simms,Maura Tierney,Jonathan Jackson,Malcolm Boddington,Katharine Isabelle,Kerry Sandomirsky,Christopher Nolan\\n\", 'unique_id': '\\nB00006JE7V:disappointing_in_more_ways_than_as_a_remake:pipboy\\n, \\n3736\\n'}\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>asin</th>\n",
        "      <th>date</th>\n",
        "      <th>helpful</th>\n",
        "      <th>product_name</th>\n",
        "      <th>product_type</th>\n",
        "      <th>rating</th>\n",
        "      <th>review</th>\n",
        "      <th>review_text</th>\n",
        "      <th>reviewer</th>\n",
        "      <th>reviewer_location</th>\n",
        "      <th>title</th>\n",
        "      <th>unique_id</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> \\nB00006IUOZ\\n</td>\n",
        "      <td>   \\nOctober 5, 2005\\n</td>\n",
        "      <td>  \\n1 of 2\\n</td>\n",
        "      <td> \\nInsomnia: Video: Al Pacino,Martin Donovan (I...</td>\n",
        "      <td> \\nvideo\\n, \\nvideo\\n</td>\n",
        "      <td> \\n2.0\\n</td>\n",
        "      <td> NaN</td>\n",
        "      <td> \\nIt's not just that this film is a bloated re...</td>\n",
        "      <td>                                   \\nPipBoy\\n</td>\n",
        "      <td> \\nparticularly the internal affairs sub-plot\\n</td>\n",
        "      <td> \\nDisappointing in more ways than as a remake\\n</td>\n",
        "      <td> \\nB00006IUOZ:disappointing_in_more_ways_than_a...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> \\nB00006JE7V\\n</td>\n",
        "      <td>   \\nOctober 5, 2005\\n</td>\n",
        "      <td>  \\n1 of 2\\n</td>\n",
        "      <td> \\nInsomnia (2002) (Spanish) (Sub): Video: Al P...</td>\n",
        "      <td> \\nvideo\\n, \\nvideo\\n</td>\n",
        "      <td> \\n2.0\\n</td>\n",
        "      <td> NaN</td>\n",
        "      <td> \\nIt's not just that this film is a bloated re...</td>\n",
        "      <td>                                   \\nPipBoy\\n</td>\n",
        "      <td> \\nparticularly the internal affairs sub-plot\\n</td>\n",
        "      <td> \\nDisappointing in more ways than as a remake\\n</td>\n",
        "      <td> \\nB00006JE7V:disappointing_in_more_ways_than_a...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> \\n1569494088\\n</td>\n",
        "      <td>     \\nJuly 28, 2004\\n</td>\n",
        "      <td> \\n0 of 18\\n</td>\n",
        "      <td> \\nSchoolhouse Rock! - America Rock: Video: Jac...</td>\n",
        "      <td> \\nvideo\\n, \\nvideo\\n</td>\n",
        "      <td> \\n1.0\\n</td>\n",
        "      <td> NaN</td>\n",
        "      <td> \\nI have rented this video for the sake of a t...</td>\n",
        "      <td> \\nCharlotte Tellson \"The Keeper of Bierce\"\\n</td>\n",
        "      <td>                                           \\n\\n</td>\n",
        "      <td>        \\nAmbrose Bierce is a Better Authority\\n</td>\n",
        "      <td> \\n1569494088:ambrose_bierce_is_a_better_author...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> \\nB00009MEB7\\n</td>\n",
        "      <td>     \\nMarch 5, 2006\\n</td>\n",
        "      <td> \\n3 of 56\\n</td>\n",
        "      <td> \\nBut I'm a Cheerleader (Spanish): Video: Nata...</td>\n",
        "      <td> \\nvideo\\n, \\nvideo\\n</td>\n",
        "      <td> \\n1.0\\n</td>\n",
        "      <td> NaN</td>\n",
        "      <td> \\nthis is another story that I don't know if I...</td>\n",
        "      <td>                      \\nEdward C. Jones III\\n</td>\n",
        "      <td>                                           \\n\\n</td>\n",
        "      <td>           \\nAmazon.com likes to take my money\\n</td>\n",
        "      <td> \\nB00009MEB7:amazon.com_likes_to_take_my_money...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> \\n080013575X\\n</td>\n",
        "      <td> \\nFebruary 16, 2003\\n</td>\n",
        "      <td>  \\n0 of 6\\n</td>\n",
        "      <td> \\nFast Forward / Movie: Video: John Scott Clou...</td>\n",
        "      <td> \\nvideo\\n, \\nvideo\\n</td>\n",
        "      <td> \\n2.0\\n</td>\n",
        "      <td> NaN</td>\n",
        "      <td> \\nhard to Believe that Sidney Poitier went fro...</td>\n",
        "      <td>      \\nmistermaxxx@yahoo.com \"mistermaxxx\"\\n</td>\n",
        "      <td>                                        \\nusa\\n</td>\n",
        "      <td>                             \\nAverage at best\\n</td>\n",
        "      <td> \\n080013575X:average_at_best:mistermaxxx@yahoo...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "             asin                   date      helpful  \\\n",
        "0  \\nB00006IUOZ\\n    \\nOctober 5, 2005\\n   \\n1 of 2\\n   \n",
        "1  \\nB00006JE7V\\n    \\nOctober 5, 2005\\n   \\n1 of 2\\n   \n",
        "2  \\n1569494088\\n      \\nJuly 28, 2004\\n  \\n0 of 18\\n   \n",
        "3  \\nB00009MEB7\\n      \\nMarch 5, 2006\\n  \\n3 of 56\\n   \n",
        "4  \\n080013575X\\n  \\nFebruary 16, 2003\\n   \\n0 of 6\\n   \n",
        "\n",
        "                                        product_name          product_type  \\\n",
        "0  \\nInsomnia: Video: Al Pacino,Martin Donovan (I...  \\nvideo\\n, \\nvideo\\n   \n",
        "1  \\nInsomnia (2002) (Spanish) (Sub): Video: Al P...  \\nvideo\\n, \\nvideo\\n   \n",
        "2  \\nSchoolhouse Rock! - America Rock: Video: Jac...  \\nvideo\\n, \\nvideo\\n   \n",
        "3  \\nBut I'm a Cheerleader (Spanish): Video: Nata...  \\nvideo\\n, \\nvideo\\n   \n",
        "4  \\nFast Forward / Movie: Video: John Scott Clou...  \\nvideo\\n, \\nvideo\\n   \n",
        "\n",
        "    rating review                                        review_text  \\\n",
        "0  \\n2.0\\n    NaN  \\nIt's not just that this film is a bloated re...   \n",
        "1  \\n2.0\\n    NaN  \\nIt's not just that this film is a bloated re...   \n",
        "2  \\n1.0\\n    NaN  \\nI have rented this video for the sake of a t...   \n",
        "3  \\n1.0\\n    NaN  \\nthis is another story that I don't know if I...   \n",
        "4  \\n2.0\\n    NaN  \\nhard to Believe that Sidney Poitier went fro...   \n",
        "\n",
        "                                       reviewer  \\\n",
        "0                                    \\nPipBoy\\n   \n",
        "1                                    \\nPipBoy\\n   \n",
        "2  \\nCharlotte Tellson \"The Keeper of Bierce\"\\n   \n",
        "3                       \\nEdward C. Jones III\\n   \n",
        "4       \\nmistermaxxx@yahoo.com \"mistermaxxx\"\\n   \n",
        "\n",
        "                                reviewer_location  \\\n",
        "0  \\nparticularly the internal affairs sub-plot\\n   \n",
        "1  \\nparticularly the internal affairs sub-plot\\n   \n",
        "2                                            \\n\\n   \n",
        "3                                            \\n\\n   \n",
        "4                                         \\nusa\\n   \n",
        "\n",
        "                                             title  \\\n",
        "0  \\nDisappointing in more ways than as a remake\\n   \n",
        "1  \\nDisappointing in more ways than as a remake\\n   \n",
        "2         \\nAmbrose Bierce is a Better Authority\\n   \n",
        "3            \\nAmazon.com likes to take my money\\n   \n",
        "4                              \\nAverage at best\\n   \n",
        "\n",
        "                                           unique_id  \n",
        "0  \\nB00006IUOZ:disappointing_in_more_ways_than_a...  \n",
        "1  \\nB00006JE7V:disappointing_in_more_ways_than_a...  \n",
        "2  \\n1569494088:ambrose_bierce_is_a_better_author...  \n",
        "3  \\nB00009MEB7:amazon.com_likes_to_take_my_money...  \n",
        "4  \\n080013575X:average_at_best:mistermaxxx@yahoo...  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Q2: What fraction of the XML review records have two \"unique_id\" nodes? What fraction have two \"product_type\" nodes? \n",
      "\n",
      ">**8062/205823 records have two product_type and unique_id nodes**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally save the dataFrame as a csv file (you can use a Pandas builtin to do this).\n",
      "\n",
      "For the review text, you should create one file with a unique name per review containing only the review text. The names should be review_text#####.txt where ##### is the number of the review."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_texts = list(perf['review_text'])\n",
      "count = 100000\n",
      "\n",
      "# print count\n",
      "for i in range(0, 101):\n",
      "    filename = \"review_text\"\n",
      "    count = i + 100000 \n",
      "    number = str(count)\n",
      "    number = number[1:]\n",
      "    filename += number + \".txt\"\n",
      "    file = open(filename, \"w\")\n",
      "    try:\n",
      "        file.write(str(review_texts[i]))\n",
      "        file.close()\n",
      "    except UnicodeEncodeError:\n",
      "        file.write(\"N/A\")\n",
      "        file.close()\n",
      "    \n",
      "    file.close()\n",
      "\n",
      "perf.to_csv('reviews.csv', encoding='utf-8')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 2: Natural Language Parsing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the preamble for this aassignment, you put the Stanford Parser in the /opt directory, and you also created a ~/bin directory. You can use these to put Stanford Parser commands in your path without having to add several new directories to your $PATH variable. There are three commands we will need initially. \n",
      "\n",
      "Open a terminal window and create symlinks like this:\n",
      "\n",
      "<pre>ln -s /opt/StanfordParser/lexparser.sh ~/bin/lexparser.sh\n",
      "\n",
      "ln -s /opt/StanfordParser/lexparser-gui.sh ~/bin/lexparser-gui.sh\n",
      "\n",
      "ln -s /opt/StanfordParser/dependencyviewer/dependencyviewer.sh ~/bin/dependencyviewer.sh</pre>\n",
      "\n",
      "and then type:\n",
      "\n",
      "<pre>\n",
      "lexparser-gui.sh\n",
      "</pre>\n",
      "\n",
      "This brings up a GUI interface to the Stanford parser. To use it, click on \"Load Parser\" which brings up a file selection dialog. Navigate to \n",
      "\n",
      "<pre>/opt/StanfordParser/stanford-parser-3.4.1-models.jar</pre>\n",
      "\n",
      "and open it.\n",
      "\n",
      "Then you will see a list of parsers to use. Select \n",
      "<pre>englishPCFG.ser.gz</pre>\n",
      "\n",
      "You're now ready to parse some text!\n",
      "\n",
      "Click on \"Load File\" and navigate back to your A3 directory (you'll have to go all the way up to \"/\", and down through \"/home\"). Load your review text file\n",
      "\n",
      "<pre>review_text00000.txt</pre>\n",
      "\n",
      "which will display the text with the first sentence highlighted. Now click on \"Parse\" which will bring up a graphical display of the parsed sentence. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Q3: Did the sentence parse correctly? Y\n",
      "\n",
      "> **Yes** \n",
      "> It created a parse tree beginning with S -> NP, VP \n",
      "\n",
      ">> Then NP -> PRP\n",
      "\n",
      ">> VP -> VBZ, RB, SBAR\n",
      "\n",
      ">> SBAR -> RB, IN, S\n",
      "\n",
      ">> S -> NP, VP\n",
      "\n",
      ">> NP -> DT, NN\n",
      "\n",
      ">> VP -> VBZ, NP\n",
      "\n",
      ">> NP -> NP, PP\n",
      "\n",
      ">> NP -> DT, JJ, NN\n",
      "\n",
      ">> PP -> IN, NP\n",
      "\n",
      ">> NP -> DT, JJ, JJ, JJ, JJ, NN"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parse the other sentences from this file. Notice that the yellow highlight is for standard sentences (broken at periods) but that some of these sentences are broken into sentence subparts. \n",
      "\n",
      "This parse tree shows a standard (constituency) tree. Usually we will want to work with dependency trees. To view a dependency tree for the sentences in this file, do \n",
      "\n",
      "<pre>\n",
      "dependencyviewer.sh -in review_text00000.txt\n",
      "</pre>\n",
      "\n",
      "(note the extra \"-in\" option for this parser). This brings up a window with tabs for each of the sentences. click through each sentence and contrast the dependency parse tree with the constituency tree in the other window.\n",
      "\n",
      "Note: Both parsers consume quite a bit of memory so you may need to close the constituency tree viewer before starting the dependency viewer. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Q4: What are the root nodes for each sentence-like fragment in sentence 5 ? \n",
      "\n",
      "> There are three root nodes in sentence 5 all beginning with S\n",
      "\n",
      "\n",
      ">> 1.  Pacino does the method-acting bit again , taking it over the top in every single scene \n",
      "\n",
      "\n",
      ">> 2. ; Hilary Swank plays a pale imitation of her better roles as the down-to-earth hometown girl ;  and Robin Williams\n",
      "\n",
      "\n",
      ">>3. -- well , he 's Robin Williams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The parser also contains scripts for parsing text into structured output. Now run\n",
      "\n",
      "<pre>\n",
      "lexparser.sh review_text00000.txt\n",
      "</pre>\n",
      "\n",
      "You will see both constituency and dependency tree output for each sentence. These formats are ad-hoc though, and not easy for a machine to work with. You can customize the parser startup script. In the main parser directory you will find a script:\n",
      "\n",
      "<pre>\n",
      "/opt/StanfordParser/lexparser.sh\n",
      "</pre>\n",
      "\n",
      "Make your own copy of this script in the same directory, say call it:\n",
      "\n",
      "<pre>\n",
      "/opt/StanfordParser/dependencyparser.sh\n",
      "</pre>\n",
      "\n",
      "This file may not be executable, depending on how you copied it. To make sure it is, do:\n",
      "\n",
      "<pre>\n",
      "chmod 755 dependencyparser.sh\n",
      "</pre>\n",
      " \n",
      "in the Stanford Parser directory. Now open the script in an editor. It contains an invocation of the parser with the option \n",
      "\n",
      "<pre>-outputFormat \"penn,typedDependencies\"</pre>\n",
      "\n",
      "we wont need the penn format output, so you can remove \"penn\" from the options. We need XML output instead of the standard output however. To do that add this option:\n",
      "\n",
      "<pre>\n",
      "-outputFormatOptions \"xml\"\n",
      "</pre>\n",
      "\n",
      "after the -outputFormat option (yes the names are confusing). Save the file. \n",
      "\n",
      "Now from a terminal prompt, create a new symlink from your ~/bin directory to the dependencyparser.sh script. You should now be able to change to the directory containing your sentences and type:\n",
      "\n",
      "<pre>\n",
      "dependencyparser.sh review_text00000.txt\n",
      "</pre>\n",
      "\n",
      "You will see some diagnostic messages, and the XML data. The parser actually sends the XML only to stdout and the diagnostics to stderr. To get just the XML in a file you can do:\n",
      "\n",
      "<pre>\n",
      "dependencyparser.sh review_text00000.txt > review_parsed00000.xml\n",
      "</pre>\n",
      "\n",
      "Now write a bash script (or do in python if you know how to invoke shell commands) to iterate over the input files and produce parsed copies, i.e. by replacing \"00000\" in the filenames above with a series of integer indices. HINT: the bash command for integer iteration is\n",
      "\n",
      "<pre>\n",
      "for i in `seq 0 xxx`\n",
      "do\n",
      "...\n",
      "done\n",
      "</pre> \n",
      "\n",
      "and to get a fixed-length integer string in a file name do:\n",
      "\n",
      "<pre>\n",
      "fname=`printf \"review_text%05d.txt\" $i`\n",
      "</pre>\n",
      "\n",
      "NOTE: Parsing is very time-consuming. You dont have to parse all the reviews, but do at least say the first 100. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from subprocess import call\n",
      "\n",
      "for i in range(0, 101):\n",
      "    filename = \"review_text\"\n",
      "    xml_file = \"review_parsed\"\n",
      "    count = i + 100000 \n",
      "    number = str(count)\n",
      "    number = number[1:]\n",
      "    filename += number + \".txt\"\n",
      "    xml_file += number + \".xml\"\n",
      "    call('dependencyparser.sh ' + filename + ' > ' + xml_file, shell=True)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Q5: Give the total of file sizes (e.g. using \"du\" on the directory containing them) for the unparsed text files and the total for the XML parsed files. \n",
      "\n",
      "> Total file sizes:\n",
      ">> XML = 2.1 M\n",
      "\n",
      ">> text files = 416K"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 3: Reading and Tabulating Targets and Sentiment from Reviews"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the ElementTree API to read an XML dependency parse tree from the files that you just created.\n",
      "\n",
      "Write a function to recognize targets and associated sentiment. The simplest pattern is to look for a word (a noun) with an amod modifier. e.g. X amod Y, where X is the governer, and Y is the dependent. In the first sentence we have \"remake\" amod \"bloated\" for example:\n",
      "\n",
      "\"remake\" amod \"bloated\"\n",
      "\n",
      "You also have\n",
      "\n",
      "\"thriller\" amod \"quick\"\n",
      "\n",
      "\"thriler\" amod \"clean\"\n",
      "\n",
      "\"thriller\" amod \"near-perfect\"\n",
      "\n",
      "\"thriller\" amod \"minimalist\"\n",
      " \n",
      "All of this is useful sentiment information that you can put in the table. There are also more complicated relationships. e.g \"remake\" connects to the film, and \"thriller\" connects to \"remake\". So the sentiments attached to \"thriller\" *could* be inherited by \"remake\" and thence \"film\" using those links (i.e. looking for patterns of three connected nodes). I want you to think about whether those are good patterns or not. You should look at more sample sentences to decide. The sentiment connection doesnt have to be perfect. i.e. a remake doesnt have to inherit the attributes of the original film. But to some extent it does, and putting more (even noisy) sentiment connections in the table gives you more data over which to look for patterns.\n",
      "\n",
      "Write one more function that finds a pattern of (target, sentiment words or phrases). This time, define your own pattern by looking through the dependency trees output from part 2. \n",
      "\n",
      "Apply these two functions to each parsed sentence, and concatenate their outputs. Finally concatenate the lists from all sentences. From the final list, construct a dataFrame with \"target\" and \"sentiment\" columns. In the space below cut and paste the first 100 rows of this table (or less if you dont have 100 rows from all the sentences from part 2. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Q6: Put your analysis code here. <br/>\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lxml import etree\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "# function to recognize target and associated sentiment\n",
      "def word_association(filename):\n",
      "    #find target and associated sentiment\n",
      "    # find all instances for a word (noun) with amod modifier, X amod Y\n",
      "    words = []\n",
      "    parser = etree.XMLParser(recover=True)\n",
      "    dep_tree = etree.parse(filename, parser)\n",
      "    root = dep_tree.getroot()\n",
      "    sentences = list(root.findall('s'))\n",
      "    for sentence in sentences:\n",
      "        for dependency in sentence[0]:\n",
      "            w_dict = {}\n",
      "            if dependency.attrib['type'] == 'amod':\n",
      "                w_dict[\"target\"] = dependency[0].text\n",
      "                w_dict[\"sentiment\"] = dependency[1].text\n",
      "                words.append(w_dict) \n",
      "    return words\n",
      "    \n",
      "\n",
      "#function to find a pattern by looking through the dependency tree\n",
      "def find_pattern(filename): \n",
      "    word_list = []\n",
      "    parser = etree.XMLParser(recover=True)\n",
      "    dep_tree = etree.parse(filename, parser)\n",
      "    root = dep_tree.getroot()\n",
      "    sentences = list(root.findall('s'))\n",
      "    for sentence in sentences:\n",
      "        for dependency in sentence[0]:\n",
      "            w_dict = {}\n",
      "            if dependency.attrib['type'] == 'acomp':\n",
      "                w_dict[\"target\"] = dependency[0].text\n",
      "                w_dict[\"sentiment\"] = dependency[1].text\n",
      "                word_list.append(w_dict)\n",
      "    return word_list\n",
      "    \n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Q7: Put <=100 rows of your target/sentiment table below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_list_1 = word_association(\"review_parsed00000.xml\")\n",
      "word_list_2 = find_pattern(\"review_parsed00000.xml\")\n",
      "\n",
      "total_word_list = word_list_1 + word_list_2\n",
      "word_list_df = pd.DataFrame(total_word_list)\n",
      "word_list_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>sentiment</th>\n",
        "      <th>target</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>       bloated</td>\n",
        "      <td>         remake</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>         quick</td>\n",
        "      <td>       thriller</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>         clean</td>\n",
        "      <td>       thriller</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>  near-perfect</td>\n",
        "      <td>       thriller</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>    minimalist</td>\n",
        "      <td>       thriller</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>         added</td>\n",
        "      <td>       material</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>      internal</td>\n",
        "      <td>        affairs</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>    toned-down</td>\n",
        "      <td>          shell</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>    off-kilter</td>\n",
        "      <td>      detective</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>   complicated</td>\n",
        "      <td>     characters</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>         moral</td>\n",
        "      <td>     atmosphere</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>      talented</td>\n",
        "      <td>       director</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>    believable</td>\n",
        "      <td>    performance</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> method-acting</td>\n",
        "      <td>            bit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>        single</td>\n",
        "      <td>          scene</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>          pale</td>\n",
        "      <td>      imitation</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>        better</td>\n",
        "      <td>          roles</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> down-to-earth</td>\n",
        "      <td>           girl</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>          fine</td>\n",
        "      <td>   performances</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>    refreshing</td>\n",
        "      <td>         change</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>         adult</td>\n",
        "      <td> contemporaries</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td> far-too-short</td>\n",
        "      <td>   performances</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>     tacked-on</td>\n",
        "      <td>          feels</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>   unnecessary</td>\n",
        "      <td>          feels</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>          sure</td>\n",
        "      <td>           make</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "        sentiment          target\n",
        "0         bloated          remake\n",
        "1           quick        thriller\n",
        "2           clean        thriller\n",
        "3    near-perfect        thriller\n",
        "4      minimalist        thriller\n",
        "5           added        material\n",
        "6        internal         affairs\n",
        "7      toned-down           shell\n",
        "8      off-kilter       detective\n",
        "9     complicated      characters\n",
        "10          moral      atmosphere\n",
        "11       talented        director\n",
        "12     believable     performance\n",
        "13  method-acting             bit\n",
        "14         single           scene\n",
        "15           pale       imitation\n",
        "16         better           roles\n",
        "17  down-to-earth            girl\n",
        "18           fine    performances\n",
        "19     refreshing          change\n",
        "20          adult  contemporaries\n",
        "21  far-too-short    performances\n",
        "22      tacked-on           feels\n",
        "23    unnecessary           feels\n",
        "24           sure            make"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Submission\n",
      "\n",
      "Save this notebook and submit it on Canvas under Assignmnet 3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}