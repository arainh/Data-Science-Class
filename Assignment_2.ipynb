{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4800: Introduction to Data Science\n",
    "## Assignment 2: Exploratory Data Analysis\n",
    "\n",
    "**NOTE** click near here to select this cell, esc-Enter will get you into cell edit mode, shift-Enter gets you back\n",
    "\n",
    "#### **Name**: April Hudspeth\n",
    "\n",
    "#### **Student ID**: 995032557\n",
    "===\n",
    "\n",
    "## Overview\n",
    "\n",
    "Exploratory Data Analysis (EDA) is the process of examining and visualizing a novel dataset to understand its characteristics and patterns, before attempting more formal analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "\n",
    "that we'll use can downloaded from Canvas, under Assignment 2\n",
    "\n",
    "Its a dataset containing various attributes of Abalone specimens, in particular the number of \"rings\" (last column) that shows the approximate age of the specimen. The dataset is typically used to predict number of rings from other attributes.\n",
    "\n",
    "The data directory contains these files:\n",
    "\n",
    "* **abalone.data**, A csv file with data on a number of abalone specimens.\n",
    "* **abalone.names**, A text file with background information on the dataset.\n",
    "\n",
    "Create a A2 directory on your VM and download this data into it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables\n",
    "\n",
    "Complete the all the exercises below and turn in a write up in the form of an IPython notebook, that is, **an .ipynb file**.\n",
    "The write up should include your code, answers to exercise questions, and plots of results.\n",
    "The submission will be as an assignment on Canvas with this file (after your edits) as an attachment. \n",
    "\n",
    "You have to use this notebook and fill in answers inline.\n",
    "Don't forget to include answers to questions that ask for natural language responses, i.e., in English, not code!\n",
    "\n",
    "We will test your code automatically (so use the same function names as requested by the questions) and that can be executed with \"Cell > Run all\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines\n",
    "\n",
    "#### Code\n",
    "\n",
    "This assignment can be done with basic python and matplotlib.\n",
    "Feel free to use PANDAs, too, which you may find well suited to several exercises.\n",
    "\n",
    "You're not required to do your coding in iPython, so feel free to use your favorite editor or IDE.\n",
    "But when you're done, remember to put your code into an ipython notebook for your write up and make sure all cells work properly.\n",
    "\n",
    "#### Collaboration\n",
    "\n",
    "This assignment is to be done individually.  Everyone should be getting a hands on experience in this course.  You are free to discuss course material with fellow students, and we encourage you to use Internet resources to aid your understanding, but the work you turn in, including all code and answers, must be your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Reading\n",
    "\n",
    "### Exercise 0\n",
    "\n",
    "Step 0 is to read the dataset. First download it from the link above, and save it into a data directory such as the path in the cell below. Look at the first few lines of the file. Notice that most columns are numeric, but the first collumn is string with one of three values (gender). \n",
    "\n",
    "Now construct two versions of the data table. First produce a variable 'abalone_raw' which is a list of records, and each record should be a list of strings. Now construct the variable 'abalone' which is list of list of numbers from it by parsing the numeric strings to float values. For the first column, map the string values to numeric ones and create a dictionary and inverse dictionary to map between the string values and numeric values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', '0.455', '0.365', '0.095', '0.514', '0.2245', '0.101', '0.15', '15']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'F': 2, 'I': 0, 'M': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please preserve the format of this line so we can use it for automated testing.\n",
    "DATA_PATH = \"/home/datascience/HWs/A2/data/\" # Make this the /path/to/the/data`\n",
    "import re\n",
    "import csv\n",
    "from itertools import chain\n",
    "# TODO Load data files here...\n",
    "def loaddatafile(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        reader = csv.reader(f,  delimiter=',')\n",
    "        return list(reader)\n",
    "\n",
    "def rawtodata(table):\n",
    "    c = []\n",
    "    g = []\n",
    "    p = 0\n",
    "    k = {}\n",
    "\n",
    "    for i in table:\n",
    "        g.append(i[:1])\n",
    "        c.append(i[1:])\n",
    "        \n",
    "    g = chain.from_iterable(zip(*g)) \n",
    "    g = list(g)\n",
    "    s = set(g)\n",
    "\n",
    "   \n",
    "    for i in s:\n",
    "        k[i] = p\n",
    "        p = p + 1\n",
    "    \n",
    "    inverse = dict((v,key) for key, v in k.items())\n",
    "    for key in k.keys():\n",
    "        for n,i in enumerate(g):\n",
    "            if key == i:\n",
    "                g[n]= k[key] \n",
    "   \n",
    "    \n",
    "    for n,i in enumerate(c):\n",
    "        i.insert(0, g[n])\n",
    "   \n",
    "\n",
    "    return(c, k, inverse)\n",
    "    # convert the string table to a numeric one, and return dicts\n",
    "\n",
    "abalone_raw = loaddatafile(DATA_PATH + \"abalone.data\")\n",
    "print abalone_raw[0]\n",
    "abalone,adict,alkup = rawtodata(abalone_raw)\n",
    "# abalone\n",
    "adict                 # check the string -> number map for the first column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of the column names for this dataset from the Dataset description. Preserve the case and the spaces in these names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames=['Sex', 'Length', 'Diameter', 'Height', 'Whole Weight', 'Schucked Weight', 'Viscera Weight', 'Shell Weight', 'Rings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a dictionary 'coldict' mapping column name to column, and use this to define a \"getcol\" function which returns a named column from the abalone table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coldict = {col:[] for col in colnames}\n",
    "for value in abalone:\n",
    "    for i in range(len(value)):\n",
    "        coldict[colnames[i]].append(float(value[i]))\n",
    "\n",
    "\n",
    "\n",
    "def getcol(colname):\n",
    "    return coldict[colname]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: What is the min, max, average and std deviation of the Height column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13\n",
      "0.0\n",
      "0.13951639933\n",
      "0.0418220494777\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print max(coldict['Height'])\n",
    "print min(coldict['Height'])\n",
    "print sum(coldict['Height'])/ len(coldict['Height'])\n",
    "print numpy.std(coldict['Height'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.0, 0.0, 0.9916207804644481, 0.79631463906237065],\n",
       " [0.815, 0.075, 0.5239920995930099, 0.1200785362060288],\n",
       " [0.65, 0.055, 0.407881254488869, 0.099227986099363466],\n",
       " [1.13, 0.0, 0.1395163993296614, 0.041822049477699706],\n",
       " [2.8255, 0.002, 0.82874215944458, 0.49033031361377233],\n",
       " [1.488, 0.001, 0.35936748862820106, 0.22193637778166947],\n",
       " [0.76, 0.0005, 0.18059360785252604, 0.10960112830473712],\n",
       " [1.005, 0.0015, 0.23883085946851795, 0.13918600552884758],\n",
       " [29.0, 1.0, 9.933684462532918, 3.2237830658211966]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = []\n",
    "for i in range(len(colnames)):\n",
    "    summaries.append([max(coldict[colnames[i]]), min(coldict[colnames[i]]), (sum(coldict[colnames[i]])/ len(coldict[colnames[i]])), numpy.std(coldict[colnames[i]], axis=0)])\n",
    "    \n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: Now create a 3x3 grid of histograms, one for each column. Make sure your figure is large enough (should consume most of the width of the page). We recommend you use pylab, and its 'subplots' function. Include the column name as a title above each subfigure. Try to use loops rather than enumerating all 9 column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: Now ceate a grid of scatter plots for each column vs the \"Rings\" column. Use color to distinguish the sex of the specimen in each plot. Make titles of the form \"&lt;colname&gt; vs Rings\". Its fine to include \"Rings vs Rings\" as the last plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is the 3x3 histogram of each column\n",
    "# plt.rcParams['figure.figsize'] = (15,15)\n",
    "\n",
    "f, axes = plt.subplots(3,3)\n",
    "k = 3\n",
    "h = 6\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i == 0:\n",
    "            axes[i, j].hist(getcol(colnames[j]))\n",
    "            axes[i, j].set_title(colnames[j])\n",
    "        elif i == 1:\n",
    "            axes[i, j].hist(getcol(colnames[k]))\n",
    "            axes[i,j].set_title(colnames[k])\n",
    "            k = k + 1\n",
    "        else:\n",
    "            axes[i, j].hist(getcol(colnames[h]))\n",
    "            axes[i,j].set_title(colnames[h])\n",
    "            h = h + 1\n",
    "      \n",
    "\n",
    "\n",
    "rings = getcol(\"Rings\")\n",
    "sex = getcol(\"Sex\")\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "plt.show()\n",
    "# TODO create the 3x3 grid of scatter plots\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "rw2 = 3\n",
    "rw3 = 6\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i == 0:\n",
    "            axs[i, j].scatter(getcol(colnames[j]), getcol(\"Rings\"))\n",
    "            m, b = numpy.polyfit(numpy.array(getcol(colnames[j])), numpy.array(getcol(\"Rings\")), 1)\n",
    "            axs[i,j].plot(numpy.array(getcol(colnames[j])), m*numpy.array(getcol(colnames[j])) + b, '-', color='red')\n",
    "            axs[i, j].set_title(colnames[j] + \" vs\" + \" Rings\")\n",
    "        elif i == 1:\n",
    "            axs[i, j].scatter(getcol(colnames[rw2]), getcol(\"Rings\"))\n",
    "            m, b = numpy.polyfit(numpy.array(getcol(colnames[rw2])), numpy.array(getcol(\"Rings\")), 1)\n",
    "            axs[i,j].plot(numpy.array(getcol(colnames[rw2])), m*numpy.array(getcol(colnames[rw2])) + b, '-', color='red')\n",
    "            axs[i, j].set_title(colnames[rw2] + \" vs\" + \" Rings\")\n",
    "            rw2 = rw2 + 1\n",
    "        else:\n",
    "            axs[i, j].scatter(getcol(colnames[rw3]), getcol(\"Rings\"))\n",
    "            m, b = numpy.polyfit(numpy.array(getcol(colnames[rw3])), numpy.array(getcol(\"Rings\")), 1)\n",
    "            axs[i,j].plot(numpy.array(getcol(colnames[rw3])), m*numpy.array(getcol(colnames[rw3])) + b, '-', color='red')\n",
    "            axs[i, j].set_title(colnames[rw3] + \" vs\" + \" Rings\")\n",
    "            rw3 = rw3 + 1\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: Do you notice any issues with the dataset? e.g. outliers? In the Height vs Rings and Viscera Weight vs Rings there are a couple noticable outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Regression lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add regression lines to the scatter plots above as per lab 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">TODO code to generate scatter plots with regression lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Prediction Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: Next we would like to explore prediction, and find the feature that gives the best (lowest error) predictions of number of rings. You can do this with polyfit, once again predicting the Rings feature from one of the others, by adding an option to return the \"residual\" of the fit, which is a measure of its prediction error. Read the documentation for polyfit on how to do this. Then make a 3 x 3 array of residuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.37713325e-23,   2.63133893e+04,   3.23915437e+04],\n",
       "       [  3.57207389e+04,   3.07338147e+04,   2.99199168e+04],\n",
       "       [  2.90749668e+04,   2.99560836e+04,   3.64146651e+04]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "residuals = np.zeros([3,3])\n",
    "# TODO get the residuals returned by polyfit\n",
    "# Rings vs Whole Weight, x array = sorted(Whole Weight), y array = Rings\n",
    "# colnames=['Sex', 'Length', 'Diameter', 'Height', 'Whole Weight', 'Schucked Weight', 'Viscera Weight', 'Shell Weight', 'Rings']\n",
    "x = np.array(getcol(\"Shell Weight\"))\n",
    "r = []\n",
    "for c in colnames:\n",
    "    x = np.array(getcol(c))\n",
    "    y = np.array(getcol(\"Rings\"))\n",
    "    z, res, _, _, _ = np.polyfit(x, y, 1, full=True)\n",
    "    r.append(res)\n",
    "\n",
    "h = len(r) - 1  # starting from the \"Rings\" column and moving towards the \"Sex\" column\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        residuals[i,j] = r[h]\n",
    "        h = h - 1\n",
    "\n",
    "residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: What feature gives the smallest residual (other than Rings of course)? The Shell Weight gives the next lowest residual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals are sums of the squared error for all the predictions. A more useful measure is the RMS (root-mean-squared) distance for each point. This is an estimate of how far the actual rings count for a specimen is from its prediction. From the residuals above, compute the RMS value for each residual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# RMS = math.sqrt(sum([prediction1**2, prediction2**2,...,predictionN**2])/len(predictions)) = math.sqrt(residuals[i,j]/len(predictions))\n",
    "# the number of predictions is the number of values in a column\n",
    "def calc_rms():\n",
    "    r = []\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            r.append(math.sqrt(residuals[i,j]/len(getcol(\"Rings\"))))\n",
    "            \n",
    "    return r\n",
    "\n",
    "rms_residuals = calc_rms()\n",
    "\n",
    "rms_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have studied prediction without worrying about chance. The linear regression coefficient between any two data sequences of the same size will normally be non-zero due to noise. This suggests that one sequence \"predicts\" the other. e.g. pick a random woman and man from a room, then their ages are almost surely different. The age and gender attributes predict each other perfectly on this sample, but the direction of influence is completely arbitrary! Obviously this doesnt generalize.\n",
    "\n",
    "Statistical tests measure the likelihood that an observation may be due to chance if there is no \"real\" influence between two variables. The probability of the observations due to chance when there is no influence is called a p-value. You want this probability to be small, say less than 0.01. \n",
    "\n",
    "> TODO: Use the 'lingress' function from scipy.stats to perform linear fits between each data column and the rings column. Save the pvalues it returns for each fit into a 3 x 3 array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "pvalues = np.zeros([3,3])\n",
    "# TODO: fill in the pvalues array\\\n",
    "\n",
    "\n",
    "def get_p_values(pvalues):\n",
    "    p = []\n",
    "    y = np.array(getcol(\"Rings\"))\n",
    "    \n",
    "    for i in range(len(colnames)):\n",
    "        x = np.array(getcol(colnames[i]))\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x,y)\n",
    "        p.append(p_value)\n",
    "    k = len(p) - 1\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            pvalues[i,j] = p[k]\n",
    "            k = k - 1\n",
    "    return pvalues\n",
    "    \n",
    "#slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "\n",
    "pvalues = get_p_values(pvalues)\n",
    "pvalues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: Are all the p-values less than 0.01 ? yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "Please sunmit your ipython notebook on Canvas under Assignment 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
